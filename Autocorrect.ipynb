{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2aa093e-45a1-4f75-a592-cc8bf3346c3b",
   "metadata": {},
   "source": [
    "# Autocorrect\n",
    "We will implement an auto-correct system that is very effective and useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2694c5a-c557-40fe-a2a1-e71c83660b8e",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [0 - Overview](#0)\n",
    "    - [0.1 - Edit Distance](#0-1)\n",
    "- [1 - Data Preprocessing](#1)\n",
    "    - [process_data](#ex-1)\n",
    "    - [get_count](#ex-2)\n",
    "    - [get_probs](#ex-3)\n",
    "- [2 - String Manipulations](#2)\n",
    "    - [delete_letter](#ex-4)\n",
    "    - [switch_letter](#ex-5)\n",
    "    - [replace_letter](#ex-6)\n",
    "    - [insert_letter](#ex-7)\n",
    "- [3 - Combining the Edits](#3)\n",
    "    - [3.1 - Edit One Letter](#3-1)\n",
    "        - [edit_one_letter](#ex-8)\n",
    "    - [3.2 - Edit Two Letters](#3-2)\n",
    "        - [edit_two_letters](#ex-9)\n",
    "    - [3.3 - Suggest Spelling Suggestions](#3-3)\n",
    "        - [get_corrections](#ex-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934a17cf-3ed8-4a6a-a47a-ef59b36fc8cb",
   "metadata": {},
   "source": [
    "<a name='0'></a>\n",
    "## 0 - Overview\n",
    "\n",
    "we use autocorrect every day on our cell phone and computer. In this we will explore what really goes on behind the scenes. Of course, the model we are about to implement is not identical to the one used in our phone, but it is still quite good. \n",
    "\n",
    "By completing this we will learn how to: \n",
    "\n",
    "- Get a word count given a corpus\n",
    "- Get a word probability in the corpus \n",
    "- Manipulate strings \n",
    "- Filter strings \n",
    "- Implement Minimum edit distance to compare strings and to help find the optimal path for the edits. \n",
    "- Understand how dynamic programming works\n",
    "\n",
    "\n",
    "Similar systems are used everywhere. \n",
    "- For example, if we type in the word **\"I am lerningg\"**, chances are very high that we meant to write **\"learning\"**, as shown in **Figure 1**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdbd2a3-c736-4ec0-acad-ffbf4e3772af",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='images/auto-correct.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:300px;height:250px;\" /> Figure 1 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6d23c5-3c61-480e-9b88-b5b6d9a624c5",
   "metadata": {},
   "source": [
    "<a name='0-1'></a>\n",
    "### 0.1 - Edit Distance\n",
    "\n",
    "In this we will implement models that correct words that are 1 and 2 edit distances away. \n",
    "- We say two words are n edit distance away from each other when we need n edits to change one word into another. \n",
    "\n",
    "An edit could consist of one of the following options: \n",
    "\n",
    "- Delete (remove a letter): ‘hat’ => ‘at, ha, ht’\n",
    "- Switch (swap 2 adjacent letters): ‘eta’ => ‘eat, tea,...’\n",
    "- Replace (change 1 letter to another): ‘jat’ => ‘hat, rat, cat, mat, ...’\n",
    "- Insert (add a letter): ‘te’ => ‘the, ten, ate, ...’\n",
    "\n",
    "we will be using the four methods above to implement an Auto-correct. \n",
    "- To do so, we will need to compute probabilities that a certain word is correct given an input. \n",
    "\n",
    "This auto-correct we are about to implement was first created by [Peter Norvig](https://en.wikipedia.org/wiki/Peter_Norvig) in 2007. \n",
    "- His [original article](https://norvig.com/spell-correct.html) may be a useful reference for this .\n",
    "\n",
    "The goal of our spell check model is to compute the following probability:\n",
    "\n",
    "$$P(c|w) = \\frac{P(w|c)\\times P(c)}{P(w)} \\tag{Eqn-1}$$\n",
    "\n",
    "The equation above is [Bayes Rule](https://en.wikipedia.org/wiki/Bayes%27_theorem). \n",
    "- Equation 1 says that the probability of a word being correct $P(c|w) $is equal to the probability of having a certain word $w$, given that it is correct $P(w|c)$, multiplied by the probability of being correct in general $P(C)$ divided by the probability of that word $w$ appearing $P(w)$ in general.\n",
    "- To compute equation 1, we will first import a data set and then create all the probabilities that we need using that data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b51e692-51f0-4f34-b0ec-313063df3ff1",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f94275-14cd-4127-8180-54d33edca90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7aaef9-aab5-4c25-9374-cfba557b7f03",
   "metadata": {},
   "source": [
    "As in any other machine learning task, the first thing we have to do is process our data set. \n",
    "- In the real world, when we build these NLP systems, we load the datasets and process them.\n",
    "- So let's get some real world practice in pre-processing the data!\n",
    "\n",
    "our first task is to read in a file called **'shakespeare.txt'** which is found in our file directory. To look at this file we can go to `File ==> Open `. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc3fe0c-2d1d-4f49-8d22-4dd01fb4910c",
   "metadata": {},
   "source": [
    "<a name='ex-1'></a>\n",
    "### process_data\n",
    "Lets implement the function `process_data` which \n",
    "\n",
    "1) Reads in a corpus (text file)\n",
    "\n",
    "2) Changes everything to lowercase\n",
    "\n",
    "3) Returns a list of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16777faf-5dcf-476b-8adf-63a1973208f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: process_data\n",
    "def process_data(file_name):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        A file_name which is found in our current directory. we just have to read it in. \n",
    "    Output: \n",
    "        words: a list containing all the words in the corpus (text file we read) in lower case. \n",
    "    \"\"\"\n",
    "    words = [] # return this variable correctly\n",
    "\n",
    "    # step 1: read in the txt file \n",
    "    with open(file_name, 'r') as f:\n",
    "        read_data = f.read()\n",
    "    \n",
    "    # step 2: Change everything to lowercase and extract words\n",
    "    text_lowercase = read_data.lower()\n",
    "    words = re.findall(r'\\w+', text_lowercase)\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841dcefa-9cca-4557-9323-2e4c9d5ab2e0",
   "metadata": {},
   "source": [
    "Note, in the following cell, 'words' is converted to a python `set`. This eliminates any duplicate entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a567c8-b1c9-41fb-8756-f41967acbf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first ten words in the text are: \n",
      "['o', 'for', 'a', 'muse', 'of', 'fire', 'that', 'would', 'ascend', 'the']\n",
      "There are 6116 unique words in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "word_l = process_data('./data/shakespeare.txt')\n",
    "vocab = set(word_l)  # this will be our new vocabulary\n",
    "print(f\"The first ten words in the text are: \\n{word_l[0:10]}\")\n",
    "print(f\"There are {len(vocab)} unique words in the vocabulary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0051a6f-eaa5-400b-aa71-23e3a5b93b70",
   "metadata": {},
   "source": [
    "<a name='ex-2'></a>\n",
    "### get_count\n",
    "\n",
    "Lets implement a `get_count` function that returns a dictionary\n",
    "- The dictionary's keys are words\n",
    "- The value for each word is the number of times that word appears in the corpus. \n",
    "\n",
    "For example, given the following sentence: **\"I am happy because I am learning\"**, our dictionary should return the following: \n",
    "<table style=\"width:20%\">\n",
    "\n",
    "  <tr>\n",
    "    <td> <b>Key </b>  </td>\n",
    "    <td> <b>Value </b> </td> \n",
    "\n",
    "\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td> I  </td>\n",
    "    <td> 2</td> \n",
    " \n",
    "  </tr>\n",
    "   \n",
    "  <tr>\n",
    "    <td>am</td>\n",
    "    <td>2</td> \n",
    "  </tr>\n",
    "\n",
    "  <tr>\n",
    "    <td>happy</td>\n",
    "    <td>1</td> \n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>because</td>\n",
    "    <td>1</td> \n",
    "  </tr>\n",
    "  \n",
    "   <tr>\n",
    "    <td>learning</td>\n",
    "    <td>1</td> \n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "Lets implement a `get_count` which returns a dictionary where the key is a word and the value is the number of times the word appears in the list.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a8164a1-8435-41ec-8593-6cd95c89d50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: get_count\n",
    "def get_count(word_l):\n",
    "    '''\n",
    "    Input:\n",
    "        word_l: a set of words representing the corpus. \n",
    "    Output:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    '''\n",
    "    \n",
    "    word_count_dict = {}  # fill this with word counts\n",
    "    ###\n",
    "    \n",
    "    for word in word_l:\n",
    "        word_count_dict[word] = word_count_dict.get(word,0) + 1\n",
    "    ###\n",
    "    \n",
    "    return word_count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e88c3391-60fa-447e-8124-aad780a6b862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6116 key values pairs\n",
      "The count for the word 'thee' is 240\n"
     ]
    }
   ],
   "source": [
    "word_count_dict = get_count(word_l)\n",
    "print(f\"There are {len(word_count_dict)} key values pairs\")\n",
    "print(f\"The count for the word 'thee' is {word_count_dict.get('thee',0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6cba82-9398-4c00-9a51-b377d3f17777",
   "metadata": {},
   "source": [
    "<a name='ex-3'></a>\n",
    "### get_probs\n",
    "Given the dictionary of word counts, compute the probability that each word will appear if randomly selected from the corpus of words.\n",
    "\n",
    "$$P(w_i) = \\frac{C(w_i)}{M} \\tag{Eqn-2}$$\n",
    "where \n",
    "\n",
    "$C(w_i)$ is the total number of times $w_i$ appears in the corpus.\n",
    "\n",
    "$M$ is the total number of words in the corpus.\n",
    "\n",
    "For example, the probability of the word 'am' in the sentence **'I am happy because I am learning'** is:\n",
    "\n",
    "$$P(am) = \\frac{C(w_i)}{M} = \\frac {2}{7} \\tag{Eqn-3}.$$\n",
    "\n",
    "Now lets implement `get_probs` function which gives us the probability \n",
    "that a word occurs in a sample. This returns a dictionary where the keys are words, and the value for each word is its probability in the corpus of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea8089f8-b4b8-4d4a-8bc0-babc471c1c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: get_probs\n",
    "def get_probs(word_count_dict):\n",
    "    '''\n",
    "    Input:\n",
    "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
    "    Output:\n",
    "        probs: A dictionary where keys are the words and the values are the probability that a word will occur. \n",
    "    '''\n",
    "    probs = {}  # return this variable correctly\n",
    "    \n",
    "    ###\n",
    "    total_words = sum(word_count_dict.values())\n",
    "    \n",
    "    for key, item in word_count_dict.items():\n",
    "        probs[key] = item/total_words\n",
    "        \n",
    "    ###\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53bfb488-41a6-4a35-850b-b3d46be0be57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of probs is 6116\n",
      "P('thee') is 0.0045\n"
     ]
    }
   ],
   "source": [
    "probs = get_probs(word_count_dict)\n",
    "print(f\"Length of probs is {len(probs)}\")\n",
    "print(f\"P('thee') is {probs['thee']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f93d65-7d26-4a94-a83a-3e04407befd8",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - String Manipulations\n",
    "\n",
    "Now that we have computed $P(w_i)$ for all the words in the corpus, we will write a few functions to manipulate strings so that we can edit the erroneous strings and return the right spellings of the words. In this section, we will implement four functions: \n",
    "\n",
    "* `delete_letter`: given a word, it returns all the possible strings that have **one character removed**. \n",
    "* `switch_letter`: given a word, it returns all the possible strings that have **two adjacent letters switched**.\n",
    "* `replace_letter`: given a word, it returns all the possible strings that have **one character replaced by another different letter**.\n",
    "* `insert_letter`: given a word, it returns all the possible strings that have an **additional character inserted**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1dd5bb-8369-4f4e-9e51-d89135fe4cd0",
   "metadata": {},
   "source": [
    "#### List comprehensions\n",
    "\n",
    "String and list manipulation in python will often make use of a python feature called  [list comprehensions](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions). The routines below will be described as using list comprehensions, but if we would rather implement them in another way, we are free to do so as long as the result is the same. Further, the following section will provide detailed instructions on how to use list comprehensions and how to implement the desired functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5039b77-28a6-425d-bdfc-f3ac1bb56109",
   "metadata": {},
   "source": [
    "Python List Comprehensions embed a looping structure inside of a list declaration, collapsing many lines of code into a single line. they seem slightly out of order relative to for loops. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0bbfbb-8073-40c4-9977-f77afb16f380",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='images/GenericListComp3.PNG' alt=\"alternate text\" width=\"width\" height=\"height\"  style=\"width:800px;height:400px;\"/> Figure 2 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a4206a-3cdf-4285-9d06-27bdf8ab8162",
   "metadata": {},
   "source": [
    "The diagram above shows that the components of a list comprehension are the same components we would find in a typical for loop that appends to a list, but in a different order. With that in mind, we'll continue the specifics of this . We will be very descriptive for the first function, `deletes()`, and less so in later functions as we become familiar with list comprehensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67878c31-5ec1-46ea-96a4-610f083aa68c",
   "metadata": {},
   "source": [
    "<a name='ex-4'></a>\n",
    "### delete_letter\n",
    "\n",
    "Lets implement a `delete_letter()` function that, given a word, returns a list of strings with one character deleted. \n",
    "\n",
    "For example, given the word **nice**, it would return the set: {'ice', 'nce', 'nic', 'nie'}. \n",
    "\n",
    "**Step 1:** Create a list of 'splits'. This is all the ways we can split a word into Left and Right: For example,   \n",
    "'nice is split into : `[('', 'nice'), ('n', 'ice'), ('ni', 'ce'), ('nic', 'e'), ('nice', '')]`\n",
    "This is common to all four functions (delete, replace, switch, insert).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8639ead8-c931-472f-b0e3-f38333870f64",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='images/Splits1.PNG' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:650px;height:200px;\" /> Figure 3 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c391ea9-0ebd-49b4-a86b-bff0b3dee57c",
   "metadata": {},
   "source": [
    "**Step 2:** This is specific to `delete_letter`. Here, we are generating all words that result from deleting one character.  \n",
    "This can be done in a single line with a list comprehension. we can make use of this type of syntax:  \n",
    "`[f(a,b) for a, b in splits if condition]`  \n",
    "\n",
    "For our 'nice' example we get: \n",
    "['ice', 'nce', 'nie', 'nic']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef75b02-ef45-47f0-b359-5ad129132328",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='images/ListComp2.PNG' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:550px;height:300px;\" /> Figure 4 </div><div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='images/ListComp2.PNG' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:550px;height:300px;\" /> Figure 4 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "825a8dbd-a650-4f2a-a38e-a16055b80d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: deletes\n",
    "def delete_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the string/word for which we will generate all possible words \n",
    "                in the vocabulary which have 1 missing character\n",
    "    Output:\n",
    "        delete_l: a list of all possible strings obtained by deleting 1 character from word\n",
    "    '''\n",
    "    \n",
    "    delete_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    ###\n",
    "    \n",
    "    split_l = [(word[:i],word[i:]) for i in range(len(word))]\n",
    "    delete_l = [L+R[1:] for (L,R) in split_l if R]\n",
    "    \n",
    "    ###\n",
    "\n",
    "    if verbose: print(f\"input word {word}, \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
    "\n",
    "    return  delete_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7a30d45-d243-4584-b040-3b897c2d3123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word cans, \n",
      "split_l = [('', 'cans'), ('c', 'ans'), ('ca', 'ns'), ('can', 's')], \n",
      "delete_l = ['ans', 'cns', 'cas', 'can']\n"
     ]
    }
   ],
   "source": [
    "delete_word_l = delete_letter(word=\"cans\",\n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114de30e-101b-4eac-9468-79393c568d86",
   "metadata": {},
   "source": [
    "#### Note 1\n",
    "- Notice how it has the extra tuple `('cans', '')`.\n",
    "- This will be fine as long as we have checked the size of the right-side substring in tuple (L,R).\n",
    "- Can you explain why this will give us the same result for the list of deletion strings (delete_l)?\n",
    "\n",
    "```CPP\n",
    "input word cans, \n",
    "split_l = [('', 'cans'), ('c', 'ans'), ('ca', 'ns'), ('can', 's'), ('cans', '')], \n",
    "delete_l = ['ans', 'cns', 'cas', 'can']\n",
    "```\n",
    "\n",
    "#### Note 2\n",
    "If we end up getting the same word as our input word, like this:\n",
    "\n",
    "```Python\n",
    "input word cans, \n",
    "split_l = [('', 'cans'), ('c', 'ans'), ('ca', 'ns'), ('can', 's'), ('cans', '')], \n",
    "delete_l = ['ans', 'cns', 'cas', 'can', 'cans']\n",
    "```\n",
    "\n",
    "- Check how we set the `range`.\n",
    "- See if we check the length of the string on the right-side of the split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76ea0bed-6503-44ce-a83a-24727751c45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outputs of delete_letter('at') is 2\n"
     ]
    }
   ],
   "source": [
    "# test # 2\n",
    "print(f\"Number of outputs of delete_letter('at') is {len(delete_letter('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95853322-7450-4843-8f93-41a424deed56",
   "metadata": {},
   "source": [
    "<a name='ex-5'></a>\n",
    "### switch_letter\n",
    "\n",
    "**Instructions for switch_letter()**: Now implement a function that switches two letters in a word. It takes in a word and returns a list of all the possible switches of two letters **that are adjacent to each other**. \n",
    "- For example, given the word 'eta', it returns {'eat', 'tea'}, but does not return 'ate'.\n",
    "\n",
    "**Step 1:** is the same as in delete_letter()  \n",
    "**Step 2:** A list comprehension or for loop which forms strings by swapping adjacent letters. This is of the form:  \n",
    "`[f(L,R) for L, R in splits if condition]`  where 'condition' will test the length of R in a given iteration. See below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f9ef53-02c4-4f7c-9be5-f64be31d4b63",
   "metadata": {},
   "source": [
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='images/Switches1.PNG' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:600px;height:200px;\"/> Figure 5 </div>      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba25e835-c553-4102-840c-6d8fa69aae96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: switches\n",
    "def switch_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: input string\n",
    "     Output:\n",
    "        switches: a list of all possible strings with one adjacent charater switched\n",
    "    ''' \n",
    "    \n",
    "    switch_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    ###\n",
    "    split_l = [(word[:i],word[i:]) for i in range(len(word))]\n",
    "    switch_l = [L + R[1] + R[0] + R[2:] for (L,R) in split_l if len(R) >=2]\n",
    "    ###\n",
    "    \n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\") \n",
    "    \n",
    "    return switch_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1067f37-378d-48b2-af6d-6faa04550ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word = eta \n",
      "split_l = [('', 'eta'), ('e', 'ta'), ('et', 'a')] \n",
      "switch_l = ['tea', 'eat']\n"
     ]
    }
   ],
   "source": [
    "switch_word_l = switch_letter(word=\"eta\",\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3a2c6c1-5080-4749-861b-947e27ed6358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outputs of switch_letter('at') is 1\n"
     ]
    }
   ],
   "source": [
    "# test # 2\n",
    "print(f\"Number of outputs of switch_letter('at') is {len(switch_letter('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ac4871-ae53-4e8f-8482-2760cb232c53",
   "metadata": {},
   "source": [
    "<a name='ex-6'></a>\n",
    "### replace_letter\n",
    "**Instructions for replace_letter()**: Now implement a function that takes in a word and returns a list of strings with one **replaced letter** from the original word. \n",
    "\n",
    "**Step 1:** is the same as in `delete_letter()`\n",
    "\n",
    "**Step 2:** A list comprehension or for loop which form strings by replacing letters.  This can be of the form:  \n",
    "`[f(a,b,c) for a, b in splits if condition for c in string]`   Note the use of the second for loop.  \n",
    "It is expected in this routine that one or more of the replacements will include the original word. For example, replacing the first letter of 'ear' with 'e' will return 'ear'.\n",
    "\n",
    "**Step 3:** Remove the original input letter from the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e50382c-1b79-46ce-aa74-e94a1be7a4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION: replaces\n",
    "def replace_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        replaces: a list of all possible strings where we replaced one letter from the original word. \n",
    "    ''' \n",
    "    \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    \n",
    "    replace_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    ###\n",
    "    split_l = [(word[:i],word[i:]) for i in range(len(word))]\n",
    "    replace_set = set([L+l+R[1:] for (L,R) in split_l if R for l in letters])\n",
    "    \n",
    "    replace_set.discard(word)\n",
    "    ###\n",
    "    \n",
    "    # turn the set back into a list and sort it, for easier viewing\n",
    "    replace_l = sorted(list(replace_set))\n",
    "    \n",
    "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nreplace_l {replace_l}\")   \n",
    "    \n",
    "    return replace_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "badd7887-5bbd-4a3f-97d9-d4b55dc123ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word = can \n",
      "split_l = [('', 'can'), ('c', 'an'), ('ca', 'n')] \n",
      "replace_l ['aan', 'ban', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cbn', 'ccn', 'cdn', 'cen', 'cfn', 'cgn', 'chn', 'cin', 'cjn', 'ckn', 'cln', 'cmn', 'cnn', 'con', 'cpn', 'cqn', 'crn', 'csn', 'ctn', 'cun', 'cvn', 'cwn', 'cxn', 'cyn', 'czn', 'dan', 'ean', 'fan', 'gan', 'han', 'ian', 'jan', 'kan', 'lan', 'man', 'nan', 'oan', 'pan', 'qan', 'ran', 'san', 'tan', 'uan', 'van', 'wan', 'xan', 'yan', 'zan']\n"
     ]
    }
   ],
   "source": [
    "replace_l = replace_letter(word='can',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de261061-5499-4c61-8508-afa84b4f149e",
   "metadata": {},
   "source": [
    "#### Note 1\n",
    "If we get something like this:\n",
    "\n",
    "```Python\n",
    "Input word = can \n",
    "split_l = [('', 'can'), ('c', 'an'), ('ca', 'n'), ('can', '')] \n",
    "replace_l ['aan', 'ban', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cbn', 'ccn', 'cdn', 'cen', 'cfn', 'cgn', 'chn', 'cin', 'cjn', 'ckn', 'cln', 'cmn', 'cnn', 'con', 'cpn', 'cqn', 'crn', 'csn', 'ctn', 'cun', 'cvn', 'cwn', 'cxn', 'cyn', 'czn', 'dan', 'ean', 'fan', 'gan', 'han', 'ian', 'jan', 'kan', 'lan', 'man', 'nan', 'oan', 'pan', 'qan', 'ran', 'san', 'tan', 'uan', 'van', 'wan', 'xan', 'yan', 'zan']\n",
    "```\n",
    "- Notice how split_l has an extra tuple `('can', '')`, but the output is still the same, so this is okay.\n",
    "\n",
    "#### Note 2\n",
    "If we get something like this:\n",
    "```Python\n",
    "Input word = can \n",
    "split_l = [('', 'can'), ('c', 'an'), ('ca', 'n'), ('can', '')] \n",
    "replace_l ['aan', 'ban', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'cana', 'canb', 'canc', 'cand', 'cane', 'canf', 'cang', 'canh', 'cani', 'canj', 'cank', 'canl', 'canm', 'cann', 'cano', 'canp', 'canq', 'canr', 'cans', 'cant', 'canu', 'canv', 'canw', 'canx', 'cany', 'canz', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cbn', 'ccn', 'cdn', 'cen', 'cfn', 'cgn', 'chn', 'cin', 'cjn', 'ckn', 'cln', 'cmn', 'cnn', 'con', 'cpn', 'cqn', 'crn', 'csn', 'ctn', 'cun', 'cvn', 'cwn', 'cxn', 'cyn', 'czn', 'dan', 'ean', 'fan', 'gan', 'han', 'ian', 'jan', 'kan', 'lan', 'man', 'nan', 'oan', 'pan', 'qan', 'ran', 'san', 'tan', 'uan', 'van', 'wan', 'xan', 'yan', 'zan']\n",
    "```\n",
    "- Notice how there are strings that are 1 letter longer than the original word, such as `cana`.\n",
    "- Please check for the case when there is an empty string `''`, and if so, do not use that empty string when setting replace_l."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d349f34-c44b-42f7-bac9-658be300c370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outputs of replace_letter('at') is 50\n"
     ]
    }
   ],
   "source": [
    "# test # 2\n",
    "print(f\"Number of outputs of replace_letter('at') is {len(replace_letter('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f88c53-8894-4145-9ae3-06653abeb215",
   "metadata": {},
   "source": [
    "<a name='ex-7'></a>\n",
    "### insert_letter\n",
    "\n",
    "Now implement a function that takes in a word and returns a list with a letter inserted at every offset.\n",
    "\n",
    "**Step 1:** is the same as in `delete_letter()`\n",
    "\n",
    "**Step 2:** This can be a list comprehension of the form:  \n",
    "`[f(a,b,c) for a, b in splits if condition for c in string]`   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "751b4397-95de-4994-9be7-beae1b16832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: inserts\n",
    "def insert_letter(word, verbose=False):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        inserts: a set of all possible strings with one new letter inserted at every offset\n",
    "    ''' \n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    insert_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    ###\n",
    "    split_l = [(word[:i], word[i:]) for i in range(len(word)+1)]\n",
    "    insert_l = [L+l+R for (L,R) in split_l for l in letters]\n",
    "    ###\n",
    "\n",
    "    \n",
    "    if verbose: print(f\"Input word {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
    "    \n",
    "    return insert_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b83010a3-d14a-4244-a44d-8dd98370def8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word at \n",
      "split_l = [('', 'at'), ('a', 't'), ('at', '')] \n",
      "insert_l = ['aat', 'bat', 'cat', 'dat', 'eat', 'fat', 'gat', 'hat', 'iat', 'jat', 'kat', 'lat', 'mat', 'nat', 'oat', 'pat', 'qat', 'rat', 'sat', 'tat', 'uat', 'vat', 'wat', 'xat', 'yat', 'zat', 'aat', 'abt', 'act', 'adt', 'aet', 'aft', 'agt', 'aht', 'ait', 'ajt', 'akt', 'alt', 'amt', 'ant', 'aot', 'apt', 'aqt', 'art', 'ast', 'att', 'aut', 'avt', 'awt', 'axt', 'ayt', 'azt', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz']\n",
      "Number of strings output by insert_letter('at') is 78\n"
     ]
    }
   ],
   "source": [
    "insert_l = insert_letter('at', True)\n",
    "print(f\"Number of strings output by insert_letter('at') is {len(insert_l)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f904871e-282f-4a00-a957-204202dd46f7",
   "metadata": {},
   "source": [
    "#### Note 1\n",
    "\n",
    "If we get a split_l like this:\n",
    "```Python\n",
    "Input word at \n",
    "split_l = [('', 'at'), ('a', 't')] \n",
    "insert_l = ['aat', 'bat', 'cat', 'dat', 'eat', 'fat', 'gat', 'hat', 'iat', 'jat', 'kat', 'lat', 'mat', 'nat', 'oat', 'pat', 'qat', 'rat', 'sat', 'tat', 'uat', 'vat', 'wat', 'xat', 'yat', 'zat', 'aat', 'abt', 'act', 'adt', 'aet', 'aft', 'agt', 'aht', 'ait', 'ajt', 'akt', 'alt', 'amt', 'ant', 'aot', 'apt', 'aqt', 'art', 'ast', 'att', 'aut', 'avt', 'awt', 'axt', 'ayt', 'azt']\n",
    "Number of strings output by insert_letter('at') is 52\n",
    "```\n",
    "- Notice that split_l is missing the extra tuple ('at', '').  For insertion, we actually **WANT** this tuple.\n",
    "- The function is not creating all the desired output strings.\n",
    "- Check the range that we use for the for loop.\n",
    "\n",
    "#### Note 2\n",
    "If we see this:\n",
    "```Python\n",
    "Input word at \n",
    "split_l = [('', 'at'), ('a', 't'), ('at', '')] \n",
    "insert_l = ['aat', 'bat', 'cat', 'dat', 'eat', 'fat', 'gat', 'hat', 'iat', 'jat', 'kat', 'lat', 'mat', 'nat', 'oat', 'pat', 'qat', 'rat', 'sat', 'tat', 'uat', 'vat', 'wat', 'xat', 'yat', 'zat', 'aat', 'abt', 'act', 'adt', 'aet', 'aft', 'agt', 'aht', 'ait', 'ajt', 'akt', 'alt', 'amt', 'ant', 'aot', 'apt', 'aqt', 'art', 'ast', 'att', 'aut', 'avt', 'awt', 'axt', 'ayt', 'azt']\n",
    "Number of strings output by insert_letter('at') is 52\n",
    "```\n",
    "\n",
    "- Even though we may have fixed the split_l so that it contains the tuple `('at', '')`, notice that you're still missing some output strings.\n",
    "    - Notice that it's missing strings such as 'ata', 'atb', 'atc' all the way to 'atz'.\n",
    "- To fix this, make sure that when we set insert_l, we allow the use of the empty string `''`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26da0798-bcb2-4201-b8ac-7c7608dca7b7",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Combining the Edits\n",
    "\n",
    "Now that we have implemented the string manipulations, we will create two functions that, given a string, will return all the possible single and double edits on that string. These will be `edit_one_letter()` and `edit_two_letters()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1023dd8f-6c66-4569-a2d7-ea0f2e4dcd91",
   "metadata": {},
   "source": [
    "<a name='3-1'></a>\n",
    "### 3.1 - Edit One Letter\n",
    "\n",
    "<a name='ex-8'></a>\n",
    "### edit_one_letter\n",
    "\n",
    "Lets implement the `edit_one_letter` function to get all the possible edits that are one edit away from a word. The edits  consist of the replace, insert, delete, and optionally the switch operation. we should use the previous functions we have already implemented to complete this function. The 'switch' function  is a less common edit function, so its use will be selected by an \"allow_switches\" input argument.\n",
    "\n",
    "Note that those functions return *lists* while this function should return a *python set*. Utilizing a set eliminates any duplicate entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c9543c1-dfe2-4f4c-9944-31588a301e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: edit_one_letter\n",
    "def edit_one_letter(word, allow_switches = True):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        word: the string/word for which we will generate all possible wordsthat are one edit away.\n",
    "    Output:\n",
    "        edit_one_set: a set of words with one possible edit. Please return a set. and not a list.\n",
    "    \"\"\"\n",
    "    \n",
    "    edit_one_set = set()\n",
    "    \n",
    "    ### \n",
    "    \n",
    "    if allow_switches: \n",
    "        edit_one_set = set(insert_letter(word) + replace_letter(word) + delete_letter(word) + switch_letter(word))\n",
    "    else:\n",
    "        edit_one_set = set(insert_letter(word) + replace_letter(word) + delete_letter(word))\n",
    "        \n",
    "    ###\n",
    "    \n",
    "    # return this as a set and not a list\n",
    "    return set(edit_one_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5584d92a-6d65-4dbc-99ea-7379ba11a8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input word at \n",
      "edit_one_l \n",
      "['a', 'aa', 'aat', 'ab', 'abt', 'ac', 'act', 'ad', 'adt', 'ae', 'aet', 'af', 'aft', 'ag', 'agt', 'ah', 'aht', 'ai', 'ait', 'aj', 'ajt', 'ak', 'akt', 'al', 'alt', 'am', 'amt', 'an', 'ant', 'ao', 'aot', 'ap', 'apt', 'aq', 'aqt', 'ar', 'art', 'as', 'ast', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'au', 'aut', 'av', 'avt', 'aw', 'awt', 'ax', 'axt', 'ay', 'ayt', 'az', 'azt', 'bat', 'bt', 'cat', 'ct', 'dat', 'dt', 'eat', 'et', 'fat', 'ft', 'gat', 'gt', 'hat', 'ht', 'iat', 'it', 'jat', 'jt', 'kat', 'kt', 'lat', 'lt', 'mat', 'mt', 'nat', 'nt', 'oat', 'ot', 'pat', 'pt', 'qat', 'qt', 'rat', 'rt', 'sat', 'st', 't', 'ta', 'tat', 'tt', 'uat', 'ut', 'vat', 'vt', 'wat', 'wt', 'xat', 'xt', 'yat', 'yt', 'zat', 'zt']\n",
      "\n",
      "The type of the returned object should be a set <class 'set'>\n",
      "Number of outputs from edit_one_letter('at') is 129\n"
     ]
    }
   ],
   "source": [
    "tmp_word = \"at\"\n",
    "tmp_edit_one_set = edit_one_letter(tmp_word)\n",
    "# turn this into a list to sort it, in order to view it\n",
    "tmp_edit_one_l = sorted(list(tmp_edit_one_set))\n",
    "\n",
    "print(f\"input word {tmp_word} \\nedit_one_l \\n{tmp_edit_one_l}\\n\")\n",
    "print(f\"The type of the returned object should be a set {type(tmp_edit_one_set)}\")\n",
    "print(f\"Number of outputs from edit_one_letter('at') is {len(edit_one_letter('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbccd327-b1f4-4344-9413-4067161a3171",
   "metadata": {},
   "source": [
    "<a name='3-2'></a>\n",
    "### 3.2 - Edit Two Letters\n",
    "\n",
    "<a name='ex-9'></a>\n",
    "### edit_two_letters\n",
    "\n",
    "Now we can generalize this to implement to get two edits on a word. To do so, we would have to get all the possible edits on a single word and then for each modified word, we would have to modify it again. \n",
    "\n",
    "Lets now implement the `edit_two_letters` function that returns a set of words that are two edits away. Note that creating additional edits based on the `edit_one_letter` function may 'restore' some one_edits to zero or one edits. That is allowed here. This is accounted for in get_corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b230ec10-3006-442d-98e0-9a86b80a2bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: edit_two_letters\n",
    "def edit_two_letters(word, allow_switches = True):\n",
    "    '''\n",
    "    Input:\n",
    "        word: the input string/word \n",
    "    Output:\n",
    "        edit_two_set: a set of strings with all possible two edits\n",
    "    '''\n",
    "    \n",
    "    edit_two_set = set()\n",
    "    \n",
    "    # Generate all one-edit variations of the word\n",
    "    one_edit_set = edit_one_letter(word, allow_switches)\n",
    "    \n",
    "    # Generate all one-edit variations for each of the one-edit variations\n",
    "    for w in one_edit_set:\n",
    "        edit_two_set.update(edit_one_letter(w, allow_switches))\n",
    "    \n",
    "    # return this as a set instead of a list\n",
    "    return set(edit_two_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3273c490-9fc2-470b-9cc4-38242f9de7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of strings with edit distance of two: 2654\n",
      "First 10 strings ['', 'a', 'aa', 'aaa', 'aab', 'aac', 'aad', 'aae', 'aaf', 'aag']\n",
      "Last 10 strings ['zv', 'zva', 'zw', 'zwa', 'zx', 'zxa', 'zy', 'zya', 'zz', 'zza']\n",
      "The data type of the returned object should be a set <class 'set'>\n",
      "Number of strings that are 2 edit distances from 'at' is 7154\n"
     ]
    }
   ],
   "source": [
    "tmp_edit_two_set = edit_two_letters(\"a\")\n",
    "tmp_edit_two_l = sorted(list(tmp_edit_two_set))\n",
    "print(f\"Number of strings with edit distance of two: {len(tmp_edit_two_l)}\")\n",
    "print(f\"First 10 strings {tmp_edit_two_l[:10]}\")\n",
    "print(f\"Last 10 strings {tmp_edit_two_l[-10:]}\")\n",
    "print(f\"The data type of the returned object should be a set {type(tmp_edit_two_set)}\")\n",
    "print(f\"Number of strings that are 2 edit distances from 'at' is {len(edit_two_letters('at'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516db821-800b-40d9-baec-7d588edd083c",
   "metadata": {},
   "source": [
    "<a name='3-3'></a>\n",
    "### 3.3 - Suggest Spelling Suggestions\n",
    "\n",
    "Now we will use our `edit_two_letters` function to get a set of all the possible 2 edits on our word. we will then use those strings to get the most probable word we meant to type a.k.a our typing suggestion.\n",
    "\n",
    "<a name='ex-10'></a>\n",
    "### get_corrections\n",
    "Lets implement `get_corrections`, which returns a list of zero to n possible suggestion tuples of the form (word, probability_of_word). \n",
    "\n",
    "**Step 1:** Generate suggestions for a supplied word: We'll use the edit functions we have developed. The 'suggestion algorithm' should follow this logic: \n",
    "* If the word is in the vocabulary, suggest the word. \n",
    "* Otherwise, if there are suggestions from `edit_one_letter` that are in the vocabulary, use those. \n",
    "* Otherwise, if there are suggestions from `edit_two_letters` that are in the vocabulary, use those. \n",
    "* Otherwise, suggest the input word.*  \n",
    "* The idea is that words generated from fewer edits are more likely than words with more edits.\n",
    "\n",
    "\n",
    "Note: \n",
    "- Edits of two letters may 'restore' strings to either zero or one edit. This algorithm accounts for this by preferentially selecting lower distance edits first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d07177-4423-485f-abf2-9c2d43c3c319",
   "metadata": {},
   "source": [
    "#### Short circuit\n",
    "In Python, logical operations such as `and` and `or` have two useful properties. They can operate on lists and they have ['short-circuit' behavior](https://docs.python.org/3/library/stdtypes.html). Try these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a4f1a21-fd4e-44d3-b96d-fb12f7e93e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['a', 'b']\n",
      "['Most', 'Likely']\n",
      "['least', 'of', 'all']\n"
     ]
    }
   ],
   "source": [
    "# example of logical operation on lists or sets\n",
    "print( [] and [\"a\",\"b\"] )\n",
    "print( [] or [\"a\",\"b\"] )\n",
    "#example of Short circuit behavior\n",
    "val1 =  [\"Most\",\"Likely\"] or [\"Less\",\"so\"] or [\"least\",\"of\",\"all\"]  # selects first, does not evalute remainder\n",
    "print(val1)\n",
    "val2 =  [] or [] or [\"least\",\"of\",\"all\"] # continues evaluation until there is a non-empty list\n",
    "print(val2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e63bf96-3702-49eb-aaa0-4d7919b653fc",
   "metadata": {},
   "source": [
    "The logical `or` could be used to implement the suggestion algorithm very compactly. Alternately, if/elif/else constructs could be used.\n",
    " \n",
    "**Step 2**: Create a 'best_words' dictionary where the 'key' is a suggestion and the 'value' is the probability of that word in our vocabulary. If the word is not in the vocabulary, assign it a probability of 0.\n",
    "\n",
    "**Step 3**: Select the n best suggestions. There may be fewer than n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dc77d4a-5794-4500-b7a6-07a643df9c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: get_corrections\n",
    "def get_corrections(word, probs, vocab, n=2, verbose = False):\n",
    "    '''\n",
    "    Input: \n",
    "        word: a user entered string to check for suggestions\n",
    "        probs: a dictionary that maps each word to its probability in the corpus\n",
    "        vocab: a set containing all the vocabulary\n",
    "        n: number of possible word corrections we want returned in the dictionary\n",
    "    Output: \n",
    "        n_best: a list of tuples with the most probable n corrected words and their probabilities.\n",
    "    '''\n",
    "    \n",
    "    suggestions = []\n",
    "    n_best = []\n",
    "    \n",
    "    ###\n",
    "    # get a set of suggestions words, first the one in vocab, then the ones in edit_one, the ones in edit_two and finally the word itself\n",
    "    edit_one = edit_one_letter(word, allow_switches = True)\n",
    "    edit_two = edit_two_letters(word, allow_switches = True)\n",
    "    suggestions = set([word]).intersection(vocab) or edit_one.intersection(vocab) or edit_two.intersection(vocab) or word\n",
    "    \n",
    "    # create best_words dictionary to store the words and the probability. If the word is not in the vocabulary, assign it a probability of 0.\n",
    "    best_words = {}\n",
    "    for w in suggestions: \n",
    "        best_words[w] = probs.get(w,0)\n",
    "    \n",
    "    # Select the n best suggestions. There may be fewer than n\n",
    "    counter = Counter(best_words)\n",
    "    n_best = counter.most_common(n)\n",
    "    \n",
    "    ###\n",
    "    \n",
    "    if verbose: print(\"entered word = \", word, \"\\nsuggestions = \", suggestions)\n",
    "\n",
    "    return n_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a6be759-b2aa-4a93-8105-58de1d7714e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entered word =  eer \n",
      "suggestions =  {'err', 'ere', 'her', 'er', 'deer', 'ever', 'ear'}\n",
      "word 0: her, probability 0.005260\n",
      "word 1: er, probability 0.000895\n",
      "data type of corrections <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Test our implementation - feel free to try other words in my word\n",
    "my_word = 'eer' \n",
    "tmp_corrections = get_corrections(my_word, probs, vocab, 2, verbose=True) # keep verbose=True\n",
    "for i, word_prob in enumerate(tmp_corrections):\n",
    "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")\n",
    "\n",
    "# CODE REVIEW COMMENT: using \"tmp_corrections\" insteads of \"cors\". \"cors\" is not defined\n",
    "print(f\"data type of corrections {type(tmp_corrections)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
